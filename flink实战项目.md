--基本环境准备

--检查点的设置

​     

1.maxwell对接Kafka时,需要设置分区策略

###### 2.flink dwd层实现

​			两条数据流join的方式有两种(API而且只能进行内连接):

​			 		1.基于窗口的	

​						2.基于状态的 interval join

​				Flink提供了两种水位的生成方法:

​							1.单调递增(乱序程度为零的)

​							2.有界乱序       (自己定义水位线时,可重新实现Watermark接口,重写其中的两种方法,onEvent和哦那period Emit方法)

​				Flink中每一个算子底层都有一个相对应的执行类,interval join 最底层就是connect 方法,有两个状态去维护两条流的数据,双向处理

###### 3.Flink SQL

​		executeSql :返回结果集

​		querySql : 返回一个动态表对象,需要注册到表执行环境中才可以对其进行操作

​		 内连接底层连接原理:会为参与内连接的每张表都在内存当中维护状态,而且默认状态下不会进行清理,需要设置TTL

​		左外连接的步骤:当左表数据到来时,会生成一条语句,标记为+I,当右表数据到达时,会将数据删除,标记为-D,同时将连接结果输出标记为+I(回撤流)

###### 4.lookup join 可以进行缓冲的设置,但是无法更新数据,适用于不常变化的数据

executesql,sqlquery

flink 实时处理数据的两种方式:flink Sql ,flink API	

###### 5.端到端的一致性:

​		将数据流写入到phoenix中,通过upsert (即幂等性来实现数据的一致性) 

​		将数据流写入到kafka主题中,通过事务来实现数据的一致性,即两阶段提交(检查点,barrey)

​		将数据写入到click house中通指定引擎来去重

###### 6.将数据流写入到遵守JDBC 的数据库中是使用addSinkd  

​    写入到kafka中使用sinkTo

###### 7.将流中的数据写入到click house 中时,flink程序出现反压的情况,通过攒批的来进行解决,每个并行度达到五条时往下输出数据

###### 8.click house 中 ReplacingMergeTree 去重依靠的时orderby中的字段,去版本号较高的;

###### 9.窗口:

       1. 乱序时间
          2. 允许迟到时间,窗口关闭和计算的时间

###### 10.aggreate 输入和输出的类型不一致,reduce 输入输出类型一致

###### 独立访客数是指在特定时间范围内访问网站的唯一访客数量，也就是排除了重复访问的用户后，网站的真实访客数量。计算独立访客数的方法可以采用IP地址、cookie和用户ID等多种方式。

​				以下是三种常用的计算独立访客数的方法：

1. 基于IP地址的计算方法：该方法通过记录访问者的IP地址来识别独立访客。当同一个IP地址在特定时间范围内访问网站多次时，只计算为一个独立访客。但是，由于多个用户可能共用同一个IP地址，该方法可能会出现计算偏差。
2. 基于cookie的计算方法：该方法通过在用户计算机上存储一个唯一的cookie来识别独立访客。当同一个cookie在特定时间范围内访问网站多次时，只计算为一个独立访客。但是，如果用户禁用了cookie或者使用不同的浏览器或设备访问网站，该方法也会出现计算偏差。
3. 基于用户ID的计算方法：该方法通过要求用户在注册或登录时提供唯一的用户ID来识别独立访客。当同一个用户ID在特定时间范围内访问网站多次时，只计算为一个独立访客。但是，如果网站没有要求用户注册或登录，该方法则无法使用。

需要注意的是，以上三种方法均存在一定的计算偏差，因此应根据具体情况选取合适的计算方法，并结合其他数据指标进行分析和判断。

######  flink中聚合操作只能在分组和开窗之后进行,而开窗之前必须进行分组,对吗? 

​		是的，Flink 中的聚合操作通常需要在分组和窗口操作之后进行，而在进行窗口操作之前通常需要进行分组操作。

具体来说，Flink 中的聚合操作通常是在分组操作的基础上进行的，也就是将数据按照某个或多个键进行分组，然后对每个分组中的数据进行聚合计算，例如求和、平均值等。分组操作可以使用`keyBy`函数来指定分组键，返回一个 KeyedStream。

而对于窗口操作，通常需要先对数据流进行分组，然后根据一定的时间或者元素个数等条件将数据流划分为多个不重叠的窗口，然后对每个窗口内的数据进行聚合操作。窗口操作可以使用 `window` 方法来指定窗口类型和窗口大小等参数，返回一个 WindowedStream。

因此，在 Flink 中进行聚合操作通常需要按照如下的顺序进行操作：

1. 使用 `keyBy` 方法进行分组操作，得到一个 `KeyedStream`。
2. 使用 `window` 方法进行窗口操作，得到一个 `WindowedStream`。
3. 在 `WindowedStream` 上进行聚合操作，例如 `sum`、`max` 等。

需要注意的是，Flink 中也有一些特殊的窗口类型，例如 `GlobalWindow` 和 `SessionWindow`，它们可以不需要进行分组操作就可以进行窗口操作。但是，在一般情况下，进行聚合操作通常需要按照上述顺序进行操作

sku粒度下单各窗口

1. 环境准备
2. 从kafka中读取数据
3. 过滤空数据以及类型的转换
   1. 去重(从下单事实表中读取的,订单明细,活动,优惠等进行关联,使用了左外连接,kafka主题会接受到三条消息)     去重的思路:1.状态+ 定时器    2.抵消的思想(按照唯一键分组去重)
4. 将流中的jsonobj转化为实体类对象
5. 指定watermark 以及提取事件时间字段
6. 按照sku_id 进行分组
7. 开窗
8. 聚合计算
9. 维度关联(1.基本维度关联  2.优化方式:旁路缓存(将热度数据缓冲到redis中,进行定期的清理),异步io)

